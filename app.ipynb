{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ce555d7-0495-4183-ae5a-bde236f51734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   request_id          institute             item  quantity urgency  \\\n",
      "0           1      Helping Hands  School Supplies       272    High   \n",
      "1           2  Elderly Care Home         Blankets       264     Low   \n",
      "2           3      Helping Hands    Sanitary Pads        93  Medium   \n",
      "3           4     Hope Orphanage   Drinking Water        19  Medium   \n",
      "4           5  Elderly Care Home    Sanitary Pads       185  Medium   \n",
      "\n",
      "   past_donations  consumption  anomaly_score approval  \n",
      "0               9         0.99           0.08  Genuine  \n",
      "1              44         1.73           0.45  Genuine  \n",
      "2              11         1.75           0.10  Genuine  \n",
      "3              45         1.81           0.21  Genuine  \n",
      "4              45         1.59           0.23  Genuine  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"donation_requests.csv\")\n",
    "\n",
    "# Rename columns for consistency\n",
    "df.rename(columns={\n",
    "    \"Request_ID\": \"request_id\",\n",
    "    \"Institute_Name\": \"institute\",\n",
    "    \"Item_Requested\": \"item\",\n",
    "    \"Quantity\": \"quantity\",\n",
    "    \"Urgency_Level\": \"urgency\",\n",
    "    \"Past_Donation_History\": \"past_donations\",\n",
    "    \"Consumption_Rate\": \"consumption\",\n",
    "    \"Anomaly_Score\": \"anomaly_score\",\n",
    "    \"Approval_Status\": \"approval\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert categorical columns properly\n",
    "categorical_cols = [\"institute\", \"item\", \"urgency\", \"approval\"]\n",
    "df[categorical_cols] = df[categorical_cols].astype(str)\n",
    "\n",
    "# Convert numeric columns properly\n",
    "numeric_cols = [\"quantity\", \"past_donations\", \"consumption\", \"anomaly_score\"]\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill missing numeric values with the median\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# Fill missing categorical values with \"Unknown\"\n",
    "df[categorical_cols] = df[categorical_cols].fillna(\"Unknown\")\n",
    "\n",
    "# Print first few rows to verify\n",
    "print(df.head())\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(\"cleaned_donation_requests.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c741c33-43ac-4624-8d94-5cd70ff10186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoded Categorical Features ---\n",
      "   request_id          institute             item  quantity  urgency  \\\n",
      "0           1      Helping Hands  School Supplies       272        0   \n",
      "1           2  Elderly Care Home         Blankets       264        1   \n",
      "2           3      Helping Hands    Sanitary Pads        93        2   \n",
      "3           4     Hope Orphanage   Drinking Water        19        2   \n",
      "4           5  Elderly Care Home    Sanitary Pads       185        2   \n",
      "\n",
      "   past_donations  consumption  anomaly_score  approval  \n",
      "0               9         0.99           0.08         1  \n",
      "1              44         1.73           0.45         1  \n",
      "2              11         1.75           0.10         1  \n",
      "3              45         1.81           0.21         1  \n",
      "4              45         1.59           0.23         1  \n",
      "\n",
      "--- Scaled Numerical Features ---\n",
      "   request_id          institute             item  quantity  urgency  \\\n",
      "0           1      Helping Hands  School Supplies  0.138670        0   \n",
      "1           2  Elderly Care Home         Blankets  0.082838        1   \n",
      "2           3      Helping Hands    Sanitary Pads -1.110576        2   \n",
      "3           4     Hope Orphanage   Drinking Water -1.627025        2   \n",
      "4           5  Elderly Care Home    Sanitary Pads -0.468506        2   \n",
      "\n",
      "   past_donations  consumption  anomaly_score  approval  \n",
      "0       -1.081816    -0.596263      -1.451857         1  \n",
      "1        1.298417     1.112544      -0.175287         1  \n",
      "2       -0.945803     1.158728      -1.382853         1  \n",
      "3        1.366424     1.297280      -1.003333         1  \n",
      "4        1.366424     0.789256      -0.934329         1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# ----- Encoding Categorical Features -----\n",
    "label_encoders = {}\n",
    "\n",
    "categorical_cols = [\"urgency\", \"approval\"]\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le  # Store encoders for later use\n",
    "\n",
    "print(\"\\n--- Encoded Categorical Features ---\")\n",
    "print(df.head())\n",
    "\n",
    "# ----- Feature Scaling (Optional) -----\n",
    "scaler = StandardScaler()\n",
    "numeric_features = [\"quantity\", \"past_donations\", \"consumption\", \"anomaly_score\"]\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "print(\"\\n--- Scaled Numerical Features ---\")\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeaa9f86-cb6f-45f9-b39a-24dd805baa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (8000, 5), Testing Data: (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define target variable and features\n",
    "target = \"approval\"  # Change to \"quantity\" if regression\n",
    "X = df_scaled.drop(columns=[target, \"request_id\", \"institute\", \"item\"])  # Remove non-numeric cols\n",
    "y = df_scaled[target]\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Data: {X_train.shape}, Testing Data: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50a9946a-f3e8-4337-a67a-a032b00dfd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       529\n",
      "           1       1.00      1.00      1.00      1471\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1095d83b-a3e6-4628-83a3-897465012b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.000000000000005e-06\n",
      "R² Score: 0.9999997429831179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c3d108e-9ce3-47a1-a356-4db062a0f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 20}\n",
      "Tuned Model Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       529\n",
      "           1       1.00      1.00      1.00      1471\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_grid, n_iter=10, cv=5, scoring='accuracy', random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Tuned Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abf52550-a80b-42e0-bba8-5b77ba5231c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 20}\n",
      "Tuned Model MAE: 0.0\n",
      "Tuned Model R² Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_grid, n_iter=10, cv=5, scoring='r2', random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "print(\"Tuned Model MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Tuned Model R² Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17264820-b765-4d92-afd1-b707948681af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras-tuner) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras-tuner) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras->keras-tuner) (13.9.2)\n",
      "Requirement already satisfied: namex in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras->keras-tuner) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from requests->keras-tuner) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from requests->keras-tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from requests->keras-tuner) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "847be935-b80d-4d70-b287-54c87986fefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.6265000104904175\n",
      "\n",
      "Best val_accuracy So Far: 0.9415000081062317\n",
      "Total elapsed time: 00h 00m 37s\n",
      "Best Hyperparameters: {'units': 384, 'learning_rate': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define model building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Adjust output layer based on problem type\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [0.001, 0.0001, 0.00001])),\n",
    "        loss='binary_crossentropy',  # Change based on your task (e.g., 'mse' for regression)\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Initialize tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of different models to try\n",
    "    executions_per_trial=1, \n",
    "    directory='tuning_results'\n",
    ")\n",
    "\n",
    "# Start tuning\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get the best model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps.values}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "778589ff-a203-4ca9-a31b-5303490729ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open(\"donation_fraud_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f99f4649-5c73-475e-8bc0-e9fa901504b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "with open(\"donation_fraud_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "059621fa-8eea-4bb4-81af-45d578f52ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9999997429831179\n",
      "Mean Absolute Error: 5.000000000000005e-06\n",
      "Mean Squared Error: 5.000000000000009e-08\n",
      "Root Mean Squared Error: 0.00022360679774997917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pviya\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² score (Coefficient of Determination)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# You can also use other regression metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b273b75-5702-4dcc-b59f-9f22ecb96b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\pviya\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (1.4.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\pviya\\anaconda3\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from flask) (1.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pviya\\appdata\\roaming\\python\\python312\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install flask joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bb95c-9c3e-41ca-a865-58523b13b765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [27/Feb/2025 17:25:51] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [27/Feb/2025 17:26:26] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [27/Feb/2025 17:26:26] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('donation_fraud_model.pkl')\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return app.send_static_file('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Get data from POST request\n",
    "        data = request.get_json()\n",
    "        features = np.array(data['features']).reshape(1, -1)  # Reshape input data\n",
    "        \n",
    "        # Predict using the model\n",
    "        prediction = model.predict(features)\n",
    "        \n",
    "        # Return prediction as JSON\n",
    "        return jsonify({'prediction': prediction[0]})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)  # Prevent auto-reloading in Jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdefae0-30a6-46fc-b578-798fd660ccdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
